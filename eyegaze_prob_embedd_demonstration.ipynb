{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.553295734Z",
     "start_time": "2023-11-23T22:50:24.214761298Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_all_data(directory):\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    subjects = []\n",
    "    act_classes = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            subject = filename.split(\"_\")[0].strip()\n",
    "            act_class = filename.split(\"_\")[1].split(\".\")[0].strip()\n",
    "            df = pd.read_csv(os.path.join(directory, filename), header=None)\n",
    "\n",
    "            # Add the entire first and second column as an array to the respective lists\n",
    "            left_data.append(df[0].values)\n",
    "            right_data.append(df[1].values)\n",
    "            subjects.append(subject)\n",
    "            act_classes.append(act_class)\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    combined_data = pd.DataFrame({\n",
    "        'left_data': left_data,\n",
    "        'right_data': right_data,\n",
    "        'subject': subjects,\n",
    "        'act_class': act_classes\n",
    "    })\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "def normalize_all_data(df):\n",
    "    # Concatenate all arrays in 'left_data' and 'right_data' to find the global min and max\n",
    "    all_left_data = np.concatenate(df['left_data'].tolist())\n",
    "    all_right_data = np.concatenate(df['right_data'].tolist())\n",
    "\n",
    "    left_min, left_max = all_left_data.min(), all_left_data.max()\n",
    "    right_min, right_max = all_right_data.min(), all_right_data.max()\n",
    "\n",
    "    print(f\"left_min: {left_min}, left_max: {left_max}\")\n",
    "    print(f\"right_min: {right_min}, right_max: {right_max}\")\n",
    "\n",
    "    # Define normalization functions based on the global min and max\n",
    "    def normalize(array, min_val, max_val):\n",
    "        if max_val - min_val == 0:\n",
    "            return array  # Avoid division by zero\n",
    "        return (array - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Apply normalization to each array in 'left_data' and 'right_data'\n",
    "    df['left_data'] = df['left_data'].apply(normalize, args=(left_min, left_max))\n",
    "    df['right_data'] = df['right_data'].apply(normalize, args=(right_min, right_max))\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.558519493Z",
     "start_time": "2023-11-23T22:50:24.556818284Z"
    }
   },
   "id": "445479d40e0503c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_min: -0.12492, left_max: 1.0873\n",
      "right_min: -0.19863, right_max: 1.4762\n"
     ]
    }
   ],
   "source": [
    "all_data = load_all_data(\"data/DesktopActivity/ALL\")\n",
    "all_data_normalized = normalize_all_data(all_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.668679838Z",
     "start_time": "2023-11-23T22:50:24.559938478Z"
    }
   },
   "id": "7f719cf25954ee27"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation for left_data: 0.09782551290226099\n",
      "Standard Deviation for right_data: 0.12052316716926113\n"
     ]
    }
   ],
   "source": [
    "def calculate_std_deviation(df):\n",
    "    # Concatenate all arrays in 'left_data' and 'right_data'\n",
    "    all_left_data = np.concatenate(df['left_data'].tolist())\n",
    "    all_right_data = np.concatenate(df['right_data'].tolist())\n",
    "\n",
    "    # Calculate the standard deviation for the concatenated data\n",
    "    std_dev_left = np.std(all_left_data)\n",
    "    std_dev_right = np.std(all_right_data)\n",
    "\n",
    "    # Print the standard deviations\n",
    "    print(f\"Standard Deviation for left_data: {std_dev_left}\")\n",
    "    print(f\"Standard Deviation for right_data: {std_dev_right}\")\n",
    "\n",
    "    return std_dev_left, std_dev_right\n",
    "\n",
    "# Calculate and print the standard deviations\n",
    "std_left, std_right = calculate_std_deviation(all_data_normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.673302251Z",
     "start_time": "2023-11-23T22:50:24.666292828Z"
    }
   },
   "id": "8b7feeb753b336cf"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The step size of each sample is 59, this is determined via the overlap\n"
     ]
    }
   ],
   "source": [
    "def apply_windowing(df, window_size, overlap):\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    print(f\"The step size of each sample is {step_size}, this is determined via the overlap\")\n",
    "\n",
    "    left_data_segments = []\n",
    "    right_data_segments = []\n",
    "    labels = []\n",
    "    subjects = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        left_data_array = row['left_data']\n",
    "        right_data_array = row['right_data']\n",
    "        label = row['act_class']  # or any other label you wish to use\n",
    "        subject = row['subject']\n",
    "\n",
    "        # Apply windowing for left_data\n",
    "        for i in range(0, len(left_data_array) - window_size + 1, step_size):\n",
    "            window = left_data_array[i:i + window_size]\n",
    "            left_data_segments.append(window)\n",
    "            labels.append(label)\n",
    "            subjects.append(subject)\n",
    "\n",
    "        # Apply windowing for right_data\n",
    "        for i in range(0, len(right_data_array) - window_size + 1, step_size):\n",
    "            window = right_data_array[i:i + window_size]\n",
    "            right_data_segments.append(window)\n",
    "            # Labels and subjects are the same for both left and right data\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    windowed_data = pd.DataFrame({\n",
    "        'left_data': left_data_segments,\n",
    "        'right_data': right_data_segments,\n",
    "        'label': labels,\n",
    "        'subject': subjects\n",
    "    })\n",
    "\n",
    "    return windowed_data\n",
    "windowed_data_normalized = apply_windowing(all_data_normalized, 300, 0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.727371049Z",
     "start_time": "2023-11-23T22:50:24.685534066Z"
    }
   },
   "id": "60f46d22e91e74a3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           left_data  \\\n",
      "0  [0.417828446981571, 0.4195855537773672, 0.4193...   \n",
      "1  [0.567636237646632, 0.559857121644586, 0.47971...   \n",
      "2  [0.5321888766065566, 0.5156489746085695, 0.512...   \n",
      "3  [0.49554536305291125, 0.49622180792265436, 0.4...   \n",
      "4  [0.5517480325353484, 0.5503868934681825, 0.549...   \n",
      "\n",
      "                                          right_data label subject  \n",
      "0  [0.4559507532107736, 0.45598657774221857, 0.45...  PLAY     P04  \n",
      "1  [0.4485828412435889, 0.44666622881128226, 0.41...  PLAY     P04  \n",
      "2  [0.3223133094105073, 0.3336935688995301, 0.331...  PLAY     P04  \n",
      "3  [0.36400709325722613, 0.3664909274374115, 0.36...  PLAY     P04  \n",
      "4  [0.3300633497131052, 0.33221282159980414, 0.33...  PLAY     P04  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7104 entries, 0 to 7103\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   left_data   7104 non-null   object\n",
      " 1   right_data  7104 non-null   object\n",
      " 2   label       7104 non-null   object\n",
      " 3   subject     7104 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 222.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(windowed_data_normalized.head())\n",
    "print(windowed_data_normalized.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T22:50:24.727725899Z",
     "start_time": "2023-11-23T22:50:24.727111515Z"
    }
   },
   "id": "1f59523cd9031d74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
